import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle

from models import BeamNetDropout
from utils_data import BeamDataset, inverse_transform_predictions

# ============================================================
# üîπ Configura√ß√µes
# ============================================================
DATA_DIR = "../build/output/ml_dataset_100k"  # ‚Üê MESMO DO TREINO
MODEL_PATH = "experiments_RobustScaler/beamnet_dropout_best.pt"
SAVE_DIR = os.path.dirname(MODEL_PATH)
os.makedirs(SAVE_DIR, exist_ok=True)
print(f"üìÅ Salvando gr√°ficos em: {SAVE_DIR}")

device = "mps" if torch.backends.mps.is_available() else (
         "cuda" if torch.cuda.is_available() else "cpu")
print(f"üöÄ Usando dispositivo: {device}")


# ============================================================
# üîπ Carregar modelo e scaler_y do checkpoint
# ============================================================
print(f"\nüìÇ Carregando checkpoint de: {MODEL_PATH}")
checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)

model = BeamNetDropout(input_dim=10, hidden_dim=512, dropout_p=0.05)
model.to(device)
model.eval()

# ‚úÖ CORRIGIDO: Detectar formato e carregar scaler_y do checkpoint
if isinstance(checkpoint, dict) and "model_state" in checkpoint:
    print("‚úì Formato novo detectado (com save_checkpoint)")
    model.load_state_dict(checkpoint["model_state"])
    scaler_y = pickle.loads(checkpoint["scaler_y_pickle"])  # ‚Üê CARREGA DO CHECKPOINT
    print("‚úì Scaler_y carregado do checkpoint com pickle")
else:
    # Formato antigo
    print("‚úì Formato antigo detectado (apenas state_dict)")
    model.load_state_dict(checkpoint)
    scaler_y = None
    print("‚ö†Ô∏è  Scaler_y n√£o encontrado no checkpoint, ser√° criado novo")

# Carregar dataset para pegar scaler_x
dataset = BeamDataset(DATA_DIR, n_samples=100, normalize=True)
scaler_x = dataset.scaler_x

# Se n√£o tem scaler_y no checkpoint, usa do dataset
if scaler_y is None:
    scaler_y = dataset.scaler_y
    print("   Usando scaler_y do dataset")

params = pd.read_csv(os.path.join(DATA_DIR, "parameters.csv"))


# ============================================================
# üîπ Fun√ß√£o Monte Carlo Dropout (para incerteza)
# ============================================================
def predict_with_uncertainty(model, X_tensor, n_samples=100):
    """
    ‚úÖ Executa m√∫ltiplas predi√ß√µes com dropout ativo (Monte Carlo)
    Retorna predi√ß√µes em espa√ßo TRANSFORMADO
    """
    model.train()  # Mant√©m dropout ativo
    preds = []
    with torch.no_grad():
        for _ in range(n_samples):
            pred = model(X_tensor)
            preds.append(pred.cpu().numpy())
    preds = np.array(preds)
    
    mean_pred_transformed = preds.mean(axis=0).flatten()
    std_pred_transformed = preds.std(axis=0).flatten()
    return mean_pred_transformed, std_pred_transformed


# ============================================================
# üîπ Fun√ß√£o para inverter incerteza
# ============================================================
def invert_uncertainty_mc(mean_trans, std_trans, scaler_y):
    """
    ‚úÖ Inverter m√©dia e estimar incerteza em espa√ßo original
    """
    # Converter m√©dia
    mean_original = inverse_transform_predictions(mean_trans, scaler_y)
    
    # Para o desvio padr√£o, usar propaga√ß√£o de incerteza
    lower_trans = (mean_trans - 2*std_trans).reshape(-1, 1)
    upper_trans = (mean_trans + 2*std_trans).reshape(-1, 1)
    
    lower_orig = inverse_transform_predictions(lower_trans, scaler_y).flatten()
    upper_orig = inverse_transform_predictions(upper_trans, scaler_y).flatten()
    
    # Estimar novo desvio padr√£o
    std_original = (upper_orig - lower_orig) / 4
    
    return mean_original, std_original


# ============================================================
# üîπ Fun√ß√£o para gerar e salvar gr√°fico de incerteza
# ============================================================
def plot_uncertainty(sample_idx=0, n_mc_samples=100):
    """
    ‚úÖ Gera gr√°fico com incerteza em espa√ßo ORIGINAL
    """
    print(f"\nüìä Gerando gr√°fico para amostra {sample_idx}...")
    
    df = pd.read_csv(os.path.join(DATA_DIR, f"sample_{sample_idx:04d}.csv"))
    E, I, q = params.loc[sample_idx, ["E", "I", "q"]]

    # Ordenar por posi√ß√£o x
    df = df.sort_values(by="x")
    x = df["x"].values

    # Carregar y verdadeiro (VEM)
    if "displacement_scaled" in df.columns:
        y_true_transformed = df["displacement_scaled"].values
    else:
        y_true_transformed = df["displacement"].values

    # ‚úÖ CORRIGIDO: Converter y verdadeiro para espa√ßo original
    y_true = inverse_transform_predictions(y_true_transformed, scaler_y).flatten()

    # ---- Montar features (10 features) ----
    L = 1.0
    x_scaled = x / L
    x2 = x_scaled ** 2
    x3 = x_scaled ** 3
    x4 = x_scaled ** 4

    EI = E * I
    inv_EI = 1.0 / EI
    q_over_EI = q / EI
    EI_log = np.log10(EI)
    q_log = np.log10(abs(q) + 1e-9)
    theoretical_disp = -(q * x**2 * (6*L**2 - 4*L*x + x**2)) / (24 * EI)

    X_in = np.stack([
        EI_log * np.ones_like(x),
        q_log * np.ones_like(x),
        x_scaled, x2, x3, x4,
        EI * np.ones_like(x),
        inv_EI * np.ones_like(x),
        q_over_EI * np.ones_like(x),
        theoretical_disp
    ], axis=1)

    # ---- Normalizar X ----
    X_norm = scaler_x.transform(X_in)
    X_tensor = torch.tensor(X_norm, dtype=torch.float32).to(device)

    # ---- Predi√ß√£o com incerteza (Monte Carlo Dropout) ----
    mean_pred_trans, std_pred_trans = predict_with_uncertainty(
        model, X_tensor, n_samples=n_mc_samples
    )

    # ‚úÖ CORRIGIDO: Inverter para espa√ßo original
    mean_pred, std_pred = invert_uncertainty_mc(
        mean_pred_trans, std_pred_trans, scaler_y
    )

    # ---- Plot ----
    plt.figure(figsize=(10, 6))
    plt.plot(x, y_true, "k-", linewidth=2.5, label="VEM (refer√™ncia)")
    plt.plot(x, mean_pred, "r--", linewidth=2, label="NN (predi√ß√£o m√©dia)")
    plt.fill_between(
        x,
        mean_pred - 2 * std_pred,
        mean_pred + 2 * std_pred,
        color="orange",
        alpha=0.3,
        label="¬±2œÉ (incerteza)"
    )
    plt.xlabel("Posi√ß√£o x (m)", fontsize=12)
    plt.ylabel("Deslocamento (m)", fontsize=12)
    plt.title(f"Monte Carlo Dropout - Amostra {sample_idx}\n(n_samples={n_mc_samples})", fontsize=13)
    plt.legend(fontsize=11)
    plt.grid(True, ls="--", alpha=0.6)
    plt.tight_layout()

    # ---- Salvar ----
    save_path = os.path.join(SAVE_DIR, f"uncertainty_sample_{sample_idx:04d}.png")
    plt.savefig(save_path, dpi=300)
    plt.close()

    print(f"   ‚úì Gr√°fico salvo: {save_path}")
    print(f"   Erro m√©dio: {np.mean(np.abs(mean_pred - y_true)):.6f} m")
    print(f"   Incerteza m√©dia (¬±2œÉ): {np.mean(std_pred*2):.6f} m")


# ============================================================
# üîπ Rodar para m√∫ltiplas vigas
# ============================================================
print("\nüöÄ Gerando gr√°ficos de incerteza com Monte Carlo Dropout...\n")
for idx in [0, 10, 25, 50, 75]:
    try:
        plot_uncertainty(sample_idx=idx, n_mc_samples=100)
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Erro ao processar amostra {idx}: {e}")

print("\n‚úÖ Todos os gr√°ficos foram gerados!")