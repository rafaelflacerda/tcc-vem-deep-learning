#!/usr/bin/env python3
"""
VEM Convergence Analysis Tool

This script analyzes convergence rates from JSON result files generated by 
the VEM parabolic solver. It computes L² and H¹ convergence rates and 
generates formatted tables for analysis.

Author: Paulo Akira
Date: 2024
"""

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.style as mplstyle
import seaborn as sns
from pathlib import Path
from typing import List, Dict, Tuple
import argparse
import sys


class ConvergenceAnalyzer:
    """
    Analyzes convergence rates from VEM simulation results.
    """
    
    def __init__(self, results_dir: str = "data/_output/parabolic"):
        """
        Initialize the convergence analyzer.
        
        Args:
            results_dir: Directory containing JSON result files
        """
        self.results_dir = Path(results_dir)
        self.data = []
        
    def load_json_results(self, json_files: List[str]) -> None:
        """
        Load results from JSON files.
        
        Args:
            json_files: List of JSON file paths (relative to results_dir)
        """
        self.data = []
        
        for json_file in json_files:
            file_path = self.results_dir / json_file
            
            if not file_path.exists():
                print(f"Warning: File {file_path} not found. Skipping.")
                continue
                
            try:
                with open(file_path, 'r') as f:
                    result = json.load(f)
                    
                # Extract relevant data
                mesh_info = result.get('mesh_info', {})
                results = result.get('results', {})
                config = result.get('configuration', {})
                
                data_point = {
                    'file': json_file,
                    'h': mesh_info.get('mesh_size_h', 0.0),
                    'nodes': mesh_info.get('nodes', 0),
                    'elements': mesh_info.get('elements', 0),
                    'l2_error': results.get('l2_error', 0.0),
                    'h1_error': results.get('h1_error', 0.0),
                    'max_error': results.get('max_error', 0.0),
                    'time_step': config.get('time_step', 0.0),
                    'final_time': config.get('final_time', 0.0),
                    'test_passed': results.get('test_passed', False)
                }
                
                self.data.append(data_point)
                
            except (json.JSONDecodeError, KeyError) as e:
                print(f"Error loading {json_file}: {e}")
                continue
        
        # Sort by mesh size (coarse to fine)
        self.data.sort(key=lambda x: x['h'], reverse=True)
        
        print(f"Successfully loaded {len(self.data)} result files.")
    
    def compute_convergence_rates(self) -> pd.DataFrame:
        """
        Compute L² and H¹ convergence rates.
        
        Returns:
            DataFrame with convergence analysis
        """
        if len(self.data) < 2:
            raise ValueError("Need at least 2 data points to compute convergence rates")
        
        # Create DataFrame
        df_data = []
        
        for i, data_point in enumerate(self.data):
            row = {
                'Mesh': f"{int(np.sqrt(data_point['elements']))}×{int(np.sqrt(data_point['elements']))}",
                'h': data_point['h'],
                'Nodes': data_point['nodes'],
                'Elements': data_point['elements'],
                'L²-Error': data_point['l2_error'],
                'H¹-Error': data_point['h1_error'],
                'Status': '✅ PASS' if data_point['test_passed'] else '❌ FAIL'
            }
            
            # Compute convergence rates (compared to previous mesh)
            if i > 0:
                prev_data = self.data[i-1]
                
                # h ratio
                h_ratio = prev_data['h'] / data_point['h']
                
                # Error ratios
                l2_ratio = prev_data['l2_error'] / data_point['l2_error']
                h1_ratio = prev_data['h1_error'] / data_point['h1_error']
                
                # Convergence rates: error ~ h^p => p = log(error_ratio) / log(h_ratio)
                if l2_ratio > 0 and h_ratio > 0:
                    l2_rate = np.log(l2_ratio) / np.log(h_ratio)
                    row['L²-Rate'] = l2_rate
                else:
                    row['L²-Rate'] = np.nan
                    
                if h1_ratio > 0 and h_ratio > 0:
                    h1_rate = np.log(h1_ratio) / np.log(h_ratio)
                    row['H¹-Rate'] = h1_rate
                else:
                    row['H¹-Rate'] = np.nan
            else:
                row['L²-Rate'] = np.nan
                row['H¹-Rate'] = np.nan
            
            df_data.append(row)
        
        return pd.DataFrame(df_data)
    
    def print_convergence_table(self, df: pd.DataFrame) -> None:
        """
        Print a nicely formatted convergence table.
        
        Args:
            df: DataFrame with convergence data
        """
        print("\n" + "="*80)
        print("VEM PARABOLIC CONVERGENCE ANALYSIS")
        print("="*80)
        print(f"Manufactured Solution: u(t,x,y) = exp(t) * sin(πx) * sin(πy)")
        print(f"Theoretical Rates: L² = O(h²), H¹ = O(h¹)")
        print("-"*80)
        
        # Format the table
        print(f"{'Mesh':>8} {'h':>10} {'Nodes':>7} {'Elems':>7} {'L²-Error':>12} {'H¹-Error':>12} {'L²-Rate':>9} {'H¹-Rate':>9} {'Status':>8}")
        print("-"*80)
        
        for _, row in df.iterrows():
            mesh = row['Mesh']
            h = row['h']
            nodes = row['Nodes']
            elements = row['Elements']
            l2_error = row['L²-Error']
            h1_error = row['H¹-Error']
            l2_rate = row['L²-Rate']
            h1_rate = row['H¹-Rate']
            status = row['Status']
            
            l2_rate_str = f"{l2_rate:.2f}" if not np.isnan(l2_rate) else "  -  "
            h1_rate_str = f"{h1_rate:.2f}" if not np.isnan(h1_rate) else "  -  "
            
            print(f"{mesh:>8} {h:>10.3f} {nodes:>7d} {elements:>7d} {l2_error:>12.2e} {h1_error:>12.2e} {l2_rate_str:>9} {h1_rate_str:>9} {status:>8}")
        
        print("-"*80)
        
        # Compute average rates (excluding NaN values)
        valid_l2_rates = df['L²-Rate'].dropna()
        valid_h1_rates = df['H¹-Rate'].dropna()
        
        if len(valid_l2_rates) > 0:
            avg_l2_rate = valid_l2_rates.mean()
            print(f"Average L²-Rate: {avg_l2_rate:.2f} (expected: 2.00)")
            
        if len(valid_h1_rates) > 0:
            avg_h1_rate = valid_h1_rates.mean()
            print(f"Average H¹-Rate: {avg_h1_rate:.2f} (expected: 1.00)")
        
        print("="*80)
    
    def save_results(self, df: pd.DataFrame, output_file: str = "convergence_results.csv") -> None:
        """
        Save results to CSV file.
        
        Args:
            df: DataFrame with convergence data
            output_file: Output CSV file name
        """
        # Save in data/_output/postprocessing directory
        output_dir = Path("../data/_output/postprocessing")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / output_file
        df.to_csv(output_path, index=False)
        print(f"💾 Results saved to: data/_output/postprocessing/{output_file}")
    
    def plot_convergence(self, df: pd.DataFrame, save_plots: bool = True, show_plots: bool = False) -> None:
        """
        Create beautiful convergence plots with Seaborn styling and log-scale axes.
        
        Args:
            df: DataFrame with convergence data
            save_plots: Whether to save plots to files
            show_plots: Whether to display plots interactively
        """
        # Set up Seaborn style for beautiful plots
        sns.set_style("whitegrid")
        sns.set_palette("husl")
        
        # Set up matplotlib parameters for publication quality
        plt.rcParams.update({
            'font.size': 12,
            'axes.labelsize': 14,
            'axes.titlesize': 16,
            'legend.fontsize': 12,
            'xtick.labelsize': 11,
            'ytick.labelsize': 11,
            'figure.figsize': (16, 12),
            'axes.grid': True,
            'grid.alpha': 0.3,
            'lines.linewidth': 2.5,
            'lines.markersize': 8
        })
        
        # Create figure with subplots
        fig = plt.figure(figsize=(16, 12))
        gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1], hspace=0.3, wspace=0.25)
        
        # Main title
        fig.suptitle('VEM Parabolic Convergence Analysis\nManufactured Solution: u(t,x,y) = exp(t)·sin(πx)·sin(πy)', 
                     fontsize=18, fontweight='bold', y=0.95)
        
        # Extract data
        h_values = df['h'].values
        l2_errors = df['L²-Error'].values
        h1_errors = df['H¹-Error'].values
        
        # Plot 1: L² Error vs h (log-log scale) - Top Left
        ax1 = fig.add_subplot(gs[0, 0])
        
        # Plot data points and line
        ax1.loglog(h_values, l2_errors, 'o-', linewidth=3, markersize=10, 
                  color=sns.color_palette("husl")[0], label='L² Error', alpha=0.8)
        
        # Add theoretical slope line
        h_theory = np.array([h_values.min(), h_values.max()])
        l2_theory = l2_errors[-1] * (h_theory / h_values[-1])**2  # O(h²) line
        ax1.loglog(h_theory, l2_theory, '--', linewidth=2.5, 
                  color='red', alpha=0.7, label='O(h²) theoretical')
        
        ax1.set_xlabel('Mesh Size h', fontweight='bold')
        ax1.set_ylabel('L² Error', fontweight='bold')
        ax1.set_title('L² Error Convergence', fontweight='bold', pad=20)
        ax1.legend(frameon=True, fancybox=True, shadow=True)
        ax1.grid(True, alpha=0.3)
        
        # Plot 2: H¹ Error vs h (log-log scale) - Top Right
        ax2 = fig.add_subplot(gs[0, 1])
        
        ax2.loglog(h_values, h1_errors, 's-', linewidth=3, markersize=10, 
                  color=sns.color_palette("husl")[2], label='H¹ Error', alpha=0.8)
        
        # Add theoretical slope line
        h1_theory = h1_errors[-1] * (h_theory / h_values[-1])**1  # O(h¹) line
        ax2.loglog(h_theory, h1_theory, '--', linewidth=2.5, 
                  color='red', alpha=0.7, label='O(h¹) theoretical')
        
        ax2.set_xlabel('Mesh Size h', fontweight='bold')
        ax2.set_ylabel('H¹ Error', fontweight='bold')
        ax2.set_title('H¹ Error Convergence', fontweight='bold', pad=20)
        ax2.legend(frameon=True, fancybox=True, shadow=True)
        ax2.grid(True, alpha=0.3)
        
        # Plot 3: Convergence Rates - Middle spanning both columns
        ax3 = fig.add_subplot(gs[1, :])
        
        valid_indices = ~np.isnan(df['L²-Rate'].values)
        if np.any(valid_indices):
            mesh_labels = df['Mesh'].values[valid_indices]
            l2_rates = df['L²-Rate'].values[valid_indices]
            h1_rates = df['H¹-Rate'].values[valid_indices]
            
            # Create DataFrame for Seaborn
            rates_data = []
            for i, mesh in enumerate(mesh_labels):
                rates_data.append({'Mesh': mesh, 'Rate': l2_rates[i], 'Type': 'L² Rate'})
                rates_data.append({'Mesh': mesh, 'Rate': h1_rates[i], 'Type': 'H¹ Rate'})
            
            rates_df = pd.DataFrame(rates_data)
            
            # Create grouped bar plot with Seaborn
            sns.barplot(data=rates_df, x='Mesh', y='Rate', hue='Type', ax=ax3, 
                       palette=['skyblue', 'lightcoral'], alpha=0.8)
            
            # Add theoretical rate lines
            ax3.axhline(y=2.0, color='blue', linestyle='--', linewidth=2, alpha=0.7, label='L² Theoretical (2.0)')
            ax3.axhline(y=1.0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='H¹ Theoretical (1.0)')
            
            ax3.set_xlabel('Mesh Refinement', fontweight='bold')
            ax3.set_ylabel('Convergence Rate', fontweight='bold')
            ax3.set_title('Observed Convergence Rates vs Theoretical', fontweight='bold', pad=20)
            ax3.legend(frameon=True, fancybox=True, shadow=True)
            
            # Add value annotations
            for i, (l2_rate, h1_rate) in enumerate(zip(l2_rates, h1_rates)):
                ax3.text(i-0.2, l2_rate + 0.05, f'{l2_rate:.2f}', ha='center', va='bottom', fontweight='bold')
                ax3.text(i+0.2, h1_rate + 0.05, f'{h1_rate:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # Plot 4: Error Reduction Factors - Bottom spanning both columns
        ax4 = fig.add_subplot(gs[2, :])
        
        if len(df) > 1:
            mesh_transitions = []
            l2_reductions = []
            h1_reductions = []
            
            for i in range(1, len(df)):
                prev_mesh = df.iloc[i-1]['Mesh']
                curr_mesh = df.iloc[i]['Mesh']
                mesh_transitions.append(f"{prev_mesh} → {curr_mesh}")
                
                l2_reduction = df.iloc[i-1]['L²-Error'] / df.iloc[i]['L²-Error']
                h1_reduction = df.iloc[i-1]['H¹-Error'] / df.iloc[i]['H¹-Error']
                
                l2_reductions.append(l2_reduction)
                h1_reductions.append(h1_reduction)
            
            # Create DataFrame for Seaborn
            reduction_data = []
            for i, transition in enumerate(mesh_transitions):
                reduction_data.append({'Transition': transition, 'Reduction': l2_reductions[i], 'Type': 'L² Error Reduction'})
                reduction_data.append({'Transition': transition, 'Reduction': h1_reductions[i], 'Type': 'H¹ Error Reduction'})
            
            reduction_df = pd.DataFrame(reduction_data)
            
            # Create grouped bar plot
            sns.barplot(data=reduction_df, x='Transition', y='Reduction', hue='Type', ax=ax4,
                       palette=['orange', 'purple'], alpha=0.8)
            
            ax4.set_xlabel('Mesh Refinement Transition', fontweight='bold')
            ax4.set_ylabel('Error Reduction Factor', fontweight='bold')
            ax4.set_title('Error Reduction Between Consecutive Mesh Levels', fontweight='bold', pad=20)
            ax4.legend(frameon=True, fancybox=True, shadow=True)
            
            # Rotate x-axis labels for better readability
            plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
            
            # Add value annotations
            for i, (l2_red, h1_red) in enumerate(zip(l2_reductions, h1_reductions)):
                ax4.text(i-0.2, l2_red + 0.1, f'{l2_red:.1f}×', ha='center', va='bottom', fontweight='bold')
                ax4.text(i+0.2, h1_red + 0.1, f'{h1_red:.1f}×', ha='center', va='bottom', fontweight='bold')
        
        # Save individual plots to data/_output/postprocessing directory
        if save_plots:
            # Create output directory
            output_dir = Path("../data/_output/postprocessing")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # Save each subplot as individual PNG files
            print(f"📊 Saving individual convergence plots...")
            
            # Save L² Error plot
            fig1, ax1_new = plt.subplots(figsize=(10, 8))
            ax1_new.loglog(h_values, l2_errors, 'o-', linewidth=3, markersize=10, 
                          color=sns.color_palette("husl")[0], label='L² Error', alpha=0.8)
            ax1_new.loglog(h_theory, l2_theory, '--', linewidth=2.5, 
                          color='red', alpha=0.7, label='O(h²) theoretical')
            ax1_new.set_xlabel('Mesh Size h', fontweight='bold')
            ax1_new.set_ylabel('L² Error', fontweight='bold')
            ax1_new.set_title('VEM L² Error Convergence\nManufactured Solution: u(t,x,y) = exp(t)·sin(πx)·sin(πy)', 
                             fontweight='bold', pad=20)
            ax1_new.legend(frameon=True, fancybox=True, shadow=True)
            ax1_new.grid(True, alpha=0.3)
            
            l2_path = output_dir / "l2_error_convergence.png"
            fig1.savefig(l2_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close(fig1)
            
            # Save H¹ Error plot
            fig2, ax2_new = plt.subplots(figsize=(10, 8))
            ax2_new.loglog(h_values, h1_errors, 's-', linewidth=3, markersize=10, 
                          color=sns.color_palette("husl")[2], label='H¹ Error', alpha=0.8)
            ax2_new.loglog(h_theory, h1_theory, '--', linewidth=2.5, 
                          color='red', alpha=0.7, label='O(h¹) theoretical')
            ax2_new.set_xlabel('Mesh Size h', fontweight='bold')
            ax2_new.set_ylabel('H¹ Error', fontweight='bold')
            ax2_new.set_title('VEM H¹ Error Convergence\nManufactured Solution: u(t,x,y) = exp(t)·sin(πx)·sin(πy)', 
                             fontweight='bold', pad=20)
            ax2_new.legend(frameon=True, fancybox=True, shadow=True)
            ax2_new.grid(True, alpha=0.3)
            
            h1_path = output_dir / "h1_error_convergence.png"
            fig2.savefig(h1_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close(fig2)
            
            # Save Convergence Rates plot
            if np.any(valid_indices):
                fig3, ax3_new = plt.subplots(figsize=(12, 8))
                sns.barplot(data=rates_df, x='Mesh', y='Rate', hue='Type', ax=ax3_new, 
                           palette=['skyblue', 'lightcoral'], alpha=0.8)
                ax3_new.axhline(y=2.0, color='blue', linestyle='--', linewidth=2, alpha=0.7, label='L² Theoretical (2.0)')
                ax3_new.axhline(y=1.0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='H¹ Theoretical (1.0)')
                ax3_new.set_xlabel('Mesh Refinement', fontweight='bold')
                ax3_new.set_ylabel('Convergence Rate', fontweight='bold')
                ax3_new.set_title('VEM Convergence Rates vs Theoretical\nManufactured Solution: u(t,x,y) = exp(t)·sin(πx)·sin(πy)', 
                                 fontweight='bold', pad=20)
                ax3_new.legend(frameon=True, fancybox=True, shadow=True)
                
                # Add value annotations
                mesh_labels = df['Mesh'].values[valid_indices]
                l2_rates = df['L²-Rate'].values[valid_indices]
                h1_rates = df['H¹-Rate'].values[valid_indices]
                for i, (l2_rate, h1_rate) in enumerate(zip(l2_rates, h1_rates)):
                    ax3_new.text(i-0.2, l2_rate + 0.05, f'{l2_rate:.2f}', ha='center', va='bottom', fontweight='bold')
                    ax3_new.text(i+0.2, h1_rate + 0.05, f'{h1_rate:.2f}', ha='center', va='bottom', fontweight='bold')
                
                rates_path = output_dir / "convergence_rates.png"
                fig3.savefig(rates_path, dpi=300, bbox_inches='tight', facecolor='white')
                plt.close(fig3)
            
            # Save Error Reduction plot
            if len(df) > 1:
                fig4, ax4_new = plt.subplots(figsize=(12, 8))
                sns.barplot(data=reduction_df, x='Transition', y='Reduction', hue='Type', ax=ax4_new,
                           palette=['orange', 'purple'], alpha=0.8)
                ax4_new.set_xlabel('Mesh Refinement Transition', fontweight='bold')
                ax4_new.set_ylabel('Error Reduction Factor', fontweight='bold')
                ax4_new.set_title('VEM Error Reduction Between Mesh Levels\nManufactured Solution: u(t,x,y) = exp(t)·sin(πx)·sin(πy)', 
                                 fontweight='bold', pad=20)
                ax4_new.legend(frameon=True, fancybox=True, shadow=True)
                plt.setp(ax4_new.get_xticklabels(), rotation=45, ha='right')
                
                # Add value annotations
                mesh_transitions = []
                l2_reductions = []
                h1_reductions = []
                for i in range(1, len(df)):
                    prev_mesh = df.iloc[i-1]['Mesh']
                    curr_mesh = df.iloc[i]['Mesh']
                    mesh_transitions.append(f"{prev_mesh} → {curr_mesh}")
                    l2_reduction = df.iloc[i-1]['L²-Error'] / df.iloc[i]['L²-Error']
                    h1_reduction = df.iloc[i-1]['H¹-Error'] / df.iloc[i]['H¹-Error']
                    l2_reductions.append(l2_reduction)
                    h1_reductions.append(h1_reduction)
                
                for i, (l2_red, h1_red) in enumerate(zip(l2_reductions, h1_reductions)):
                    ax4_new.text(i-0.2, l2_red + 0.1, f'{l2_red:.1f}×', ha='center', va='bottom', fontweight='bold')
                    ax4_new.text(i+0.2, h1_red + 0.1, f'{h1_red:.1f}×', ha='center', va='bottom', fontweight='bold')
                
                reduction_path = output_dir / "error_reduction.png"
                fig4.savefig(reduction_path, dpi=300, bbox_inches='tight', facecolor='white')
                plt.close(fig4)
            
            print(f"   • data/_output/postprocessing/{l2_path.name}")
            print(f"   • data/_output/postprocessing/{h1_path.name}")
            if np.any(valid_indices):
                print(f"   • data/_output/postprocessing/{rates_path.name}")
            if len(df) > 1:
                print(f"   • data/_output/postprocessing/{reduction_path.name}")
        
        # Show plots
        if show_plots:
            plt.show()
        else:
            plt.close()
            
        # Reset style
        sns.reset_defaults()
    
    def create_summary_report(self, df: pd.DataFrame, save_report: bool = True) -> str:
        """
        Create a comprehensive summary report.
        
        Args:
            df: DataFrame with convergence data
            save_report: Whether to save report to file
            
        Returns:
            Report text as string
        """
        report_lines = []
        report_lines.append("="*80)
        report_lines.append("VEM PARABOLIC CONVERGENCE ANALYSIS - SUMMARY REPORT")
        report_lines.append("="*80)
        report_lines.append("")
        
        # Problem description
        report_lines.append("PROBLEM SETUP:")
        report_lines.append("  PDE: ∂u/∂t - Δu = f(t,x,y)")
        report_lines.append("  Boundary: u = 0 on ∂Ω (Homogeneous Dirichlet)")
        report_lines.append("  Manufactured Solution: u(t,x,y) = exp(t) * sin(πx) * sin(πy)")
        report_lines.append("  Time Integration: RK3 with Lumped Mass Matrix")
        report_lines.append("")
        
        # Mesh information
        report_lines.append("MESH INFORMATION:")
        for _, row in df.iterrows():
            report_lines.append(f"  {row['Mesh']:>8}: h={row['h']:.3f}, {row['Nodes']:>3d} nodes, {row['Elements']:>3d} elements")
        report_lines.append("")
        
        # Error analysis
        report_lines.append("ERROR ANALYSIS:")
        report_lines.append("  Mesh     L²-Error    H¹-Error    L²-Rate  H¹-Rate")
        report_lines.append("  " + "-"*50)
        for _, row in df.iterrows():
            l2_rate = f"{row['L²-Rate']:.2f}" if not np.isnan(row['L²-Rate']) else "  -  "
            h1_rate = f"{row['H¹-Rate']:.2f}" if not np.isnan(row['H¹-Rate']) else "  -  "
            report_lines.append(f"  {row['Mesh']:>6} {row['L²-Error']:>10.2e} {row['H¹-Error']:>10.2e} {l2_rate:>8} {h1_rate:>8}")
        report_lines.append("")
        
        # Convergence summary
        valid_l2_rates = df['L²-Rate'].dropna()
        valid_h1_rates = df['H¹-Rate'].dropna()
        
        if len(valid_l2_rates) > 0:
            avg_l2_rate = valid_l2_rates.mean()
            report_lines.append(f"CONVERGENCE SUMMARY:")
            report_lines.append(f"  Average L²-Rate: {avg_l2_rate:.2f} (theoretical: 2.00)")
            report_lines.append(f"  L²-Rate Efficiency: {(avg_l2_rate/2.0)*100:.1f}%")
            
        if len(valid_h1_rates) > 0:
            avg_h1_rate = valid_h1_rates.mean()
            report_lines.append(f"  Average H¹-Rate: {avg_h1_rate:.2f} (theoretical: 1.00)")
            report_lines.append(f"  H¹-Rate Efficiency: {(avg_h1_rate/1.0)*100:.1f}%")
        
        report_lines.append("")
        
        # Performance assessment
        report_lines.append("PERFORMANCE ASSESSMENT:")
        if len(valid_l2_rates) > 0 and len(valid_h1_rates) > 0:
            l2_efficiency = (valid_l2_rates.mean() / 2.0) * 100
            h1_efficiency = (valid_h1_rates.mean() / 1.0) * 100
            
            if l2_efficiency >= 80 and h1_efficiency >= 80:
                assessment = "EXCELLENT - Both rates very close to theoretical"
            elif l2_efficiency >= 60 and h1_efficiency >= 60:
                assessment = "GOOD - Rates reasonably close to theoretical"
            else:
                assessment = "NEEDS IMPROVEMENT - Rates significantly below theoretical"
                
            report_lines.append(f"  Overall Assessment: {assessment}")
        
        report_lines.append("")
        report_lines.append("="*80)
        
        report_text = "\n".join(report_lines)
        
        if save_report:
            # Save in data/_output/postprocessing directory
            output_dir = Path("../data/_output/postprocessing")
            output_dir.mkdir(parents=True, exist_ok=True)
            report_path = output_dir / "vem_convergence_report.txt"
            with open(report_path, 'w') as f:
                f.write(report_text)
            print(f"📋 Summary report saved to: data/_output/postprocessing/{report_path.name}")
        
        return report_text


def main():
    """
    Main function for command-line usage.
    """
    parser = argparse.ArgumentParser(description="Analyze VEM convergence rates from JSON results")
    parser.add_argument("json_files", nargs="+", help="JSON result files to analyze")
    parser.add_argument("--results-dir", default="data/_output/parabolic", 
                       help="Directory containing JSON files (default: data/_output/parabolic)")
    parser.add_argument("--output", default="convergence_results.csv",
                       help="Output CSV file name (default: convergence_results.csv)")
    parser.add_argument("--no-save", action="store_true", help="Don't save results to CSV")
    parser.add_argument("--plot", action="store_true", help="Generate convergence plots")
    parser.add_argument("--show-plots", action="store_true", help="Display plots interactively")
    parser.add_argument("--report", action="store_true", help="Generate detailed summary report")
    
    args = parser.parse_args()
    
    # Initialize analyzer
    analyzer = ConvergenceAnalyzer(args.results_dir)
    
    # Load data
    analyzer.load_json_results(args.json_files)
    
    if len(analyzer.data) == 0:
        print("Error: No valid data files found.")
        sys.exit(1)
    
    # Compute convergence rates
    try:
        df = analyzer.compute_convergence_rates()
        
        # Print table
        analyzer.print_convergence_table(df)
        
        # Save results
        if not args.no_save:
            analyzer.save_results(df, args.output)
        
        # Generate plots
        if args.plot or args.show_plots:
            analyzer.plot_convergence(df, save_plots=args.plot, show_plots=args.show_plots)
        
        # Generate detailed report
        if args.report:
            analyzer.create_summary_report(df)
            
    except ValueError as e:
        print(f"Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
